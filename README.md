# PKU-TANGENT nlp-tutorial

æœ¬æ•™ç¨‹ä¾›æ–°åŠ å…¥ TANGENT å®éªŒå®¤çš„åŒå­¦å…¥é—¨ NLP ä½¿ç”¨

- [PKU-TANGENT nlp-tutorial](#pku-tangent-nlp-tutorial)
  - [å†™åœ¨å‰é¢](#å†™åœ¨å‰é¢)
  - [åŸºç¡€çŸ¥è¯†](#åŸºç¡€çŸ¥è¯†)
    - [æœºå™¨å­¦ä¹ ](#æœºå™¨å­¦ä¹ )
    - [æ·±åº¦å­¦ä¹ ](#æ·±åº¦å­¦ä¹ )
    - [è‡ªç„¶è¯­è¨€å¤„ç†](#è‡ªç„¶è¯­è¨€å¤„ç†)
  - [æ–‡çŒ®é˜…è¯»](#æ–‡çŒ®é˜…è¯»)
    - [Google Scholar](#google-scholar)
    - [ä¼šè®®è®ºæ–‡](#ä¼šè®®è®ºæ–‡)
    - [å‰æ²¿è¿›å±•](#å‰æ²¿è¿›å±•)
    - [å·¥å…·](#å·¥å…·)
  - [åŠ¨æ‰‹å®è·µ](#åŠ¨æ‰‹å®è·µ)
    - [ä»»åŠ¡ä¸€ï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„æ–‡æœ¬åˆ†ç±»](#ä»»åŠ¡ä¸€åŸºäºæ·±åº¦å­¦ä¹ çš„æ–‡æœ¬åˆ†ç±»)
    - [ä»»åŠ¡äºŒï¼šåŸºäº LSTM-CRF çš„å‘½åå®ä½“è¯†åˆ«](#ä»»åŠ¡äºŒåŸºäº-lstm-crf-çš„å‘½åå®ä½“è¯†åˆ«)
    - [ä»»åŠ¡ä¸‰ï¼šæ–°é—»æ ‡é¢˜ç”Ÿæˆ](#ä»»åŠ¡ä¸‰æ–°é—»æ ‡é¢˜ç”Ÿæˆ)
    - [ä»»åŠ¡å››ï¼šTransformer](#ä»»åŠ¡å››transformer)
  - [æœ¬ä»“åº“çš„ä½¿ç”¨è¯´æ˜](#æœ¬ä»“åº“çš„ä½¿ç”¨è¯´æ˜)

## å†™åœ¨å‰é¢

ï¼ˆéåŠé€€hhhhï¼‰åœ¨ä½ çœ‹ä»¥ä¸‹å†…å®¹ä¹‹å‰ï¼Œè¯·ç¡®ä¿ä½ æœ‰ï¼š

ç›¸ä¿¡å¤§å®¶ç»è¿‡å‡ å¹´çš„å­¦ä¹ ï¼Œå·²ç»æ‹¥æœ‰äº†ä»¥ä¸‹çš„æŠ€èƒ½ï¼š
1. ä¼˜ç§€çš„ä¿¡æ¯æ£€ç´¢èƒ½åŠ›ï¼Œæ— è®ºæ˜¯åœ¨è®ºæ–‡é˜…è¯»ã€å†™ä»£ç ã€ä½¿ç”¨æœåŠ¡å™¨ã€å†™è®ºæ–‡ç­‰è¿‡ç¨‹ä¸­éƒ½æœ‰å¯èƒ½é‡åˆ°å„ç§å„æ ·çš„é—®é¢˜ï¼Œåœ¨è¯¢é—®ä»–äººä¹‹å‰ï¼Œè¯·å–„ç”¨æœç´¢
2. ä¼˜ç§€çš„è‹±æ–‡é˜…è¯»èƒ½åŠ›å’ŒåŸºæœ¬çš„è‹±è¯­å†™ä½œèƒ½åŠ›
3. è‰¯å¥½çš„ç¼–ç¨‹èƒ½åŠ›ï¼Œåœ¨ NLP ç›¸å…³ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šä½¿ç”¨ Pythonï¼Œå¦‚æœä½ ä¹‹å‰åªå­¦è¿‡ C æˆ–è€… C++ï¼Œé‚£ä¹ˆå…¥é—¨ Python å¯¹äºä½ æ¥è¯´å°†ä¸æ˜¯ä¸€ä»¶éš¾äº‹ã€‚
æˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨ Anacondaï¼ˆMinicondaï¼‰æ¥ç®¡ç†ä¸ªäººç”µè„‘ä¹ƒè‡³ Linux æœåŠ¡å™¨ä¸Šçš„ Python ç¯å¢ƒï¼Œè¯·æå‰å®‰è£…å¹¶å­¦ä¹  conda çš„ä½¿ç”¨ã€‚
æ­¤å¤–åœ¨ç§‘ç ”ä¸­æˆ‘ä»¬ç»å¸¸ä¼šä¸ä»–äººåˆä½œï¼Œå› æ­¤è¯·ä¿æŒè‰¯å¥½çš„ä»£ç ä¹ æƒ¯ï¼Œå¦‚æœä½ ä¸äº†è§£ä»£ç è§„èŒƒï¼Œè¯·å‚è€ƒ [Google çš„ Python ä»£ç è§„èŒƒ](https://zh-google-styleguide.readthedocs.io/en/latest/google-python-styleguide/python_style_rules/)
4. æ•°å­¦åŸºç¡€ï¼Œä½œä¸ºä¸€åç†å·¥ç§‘çš„å­¦ç”Ÿï¼Œä½ åº”è¯¥å·²ç»å­¦è¿‡é«˜ç­‰æ•°å­¦ï¼ˆæ•°å­¦åˆ†æï¼‰ã€çº¿æ€§ä»£æ•°ï¼ˆé«˜ç­‰ä»£æ•°ï¼‰ã€æ¦‚ç‡è®ºä¸ç»Ÿè®¡ç­‰åŸºç¡€æ•°å­¦è¯¾ç¨‹ï¼Œåœ¨å…¥é—¨é˜¶æ®µæˆ‘ä»¬æ¶‰åŠåˆ°çš„æ•°å­¦çŸ¥è¯†è¾ƒä¸ºç®€å•ï¼Œä½†æ˜¯æ‰å®çš„æ•°ç†åŸºç¡€ä¼šæ”¯æ’‘ä½ èµ°å¾—æ›´æ·±æ›´è¿œã€‚
5. æœ€å¥½æ‹¥æœ‰ Linux ç³»ç»Ÿä½¿ç”¨ç»éªŒï¼Œç›®å‰æ˜¯æ·±åº¦å­¦ä¹ çš„æ—¶ä»£ï¼Œå¯¹äºè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œåˆæ˜¯å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„æ—¶ä»£ï¼Œä¸ªäººç”µè„‘æ— æ³•æ”¯æ’‘å¤§æ¨¡å‹çš„è®­ç»ƒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Linux æœåŠ¡å™¨è¿›è¡Œ Coding å’Œå®éªŒï¼Œæå‰äº†è§£å·¥ä½œæµç¨‹ä¼šå¤§å¤§æé«˜æ•ˆç‡ã€‚
æœ¬æ•™ç¨‹[åŠ¨æ‰‹å®è·µ](#åŠ¨æ‰‹å®è·µ)éƒ¨åˆ†åŸºäº CNN å’Œ RNNï¼ˆLSTMï¼‰çš„æ¨¡å‹ç†è®ºä¸Šå¯ä»¥åœ¨ä¸ªäººç”µè„‘ä¸Šè¿è¡Œï¼Œå¦‚éœ€ GPU èµ„æºï¼Œè¯·è”ç³»å®éªŒå®¤æœåŠ¡å™¨ç®¡ç†å‘˜ã€‚


## åŸºç¡€çŸ¥è¯†

æˆ‘ä»¬é»˜è®¤å¤§å®¶å·²ç»å®Œæˆäº†è®¡ç®—æœºä¸“ä¸šæœ¬ç§‘ä¸€å¹´çº§å’ŒäºŒå¹´çº§çš„ç›¸å…³è¯¾ç¨‹ï¼Œæ‹¥æœ‰ä¸€å®šçš„æ•°å­¦å’Œç¼–ç¨‹åŸºç¡€

### æœºå™¨å­¦ä¹ 

è™½ç„¶ç›®å‰æ˜¯æ·±åº¦å­¦ä¹ çš„æ—¶ä»£ï¼Œæˆ‘ä»¬ä¹Ÿå¾ˆå°‘ä½¿ç”¨ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„ç®—æ³•æ¥è§£å†³é—®é¢˜ï¼Œä½†æ˜¯ä¸€æ–¹é¢ä¸€äº›åŸºç¡€æ¦‚å¿µä»ç„¶æ˜¯ç›¸é€šçš„ï¼Œå¦ä¸€æ–¹é¢ç»å…¸æœºå™¨å­¦ä¹ ç®—æ³•çš„æ€æƒ³ï¼Œå¦‚ EMã€LDA ç­‰ï¼Œåœ¨æ·±åº¦å­¦ä¹ æ—¶ä»£å¾€å¾€èƒ½å¤Ÿå†ä¹…å¼¥æ–°ï¼Œä»¥å¦ä¸€ç§æ–¹å¼ç„•å‘å‡ºæ–°çš„å…‰å½©ã€‚
å¯¹äºæƒ³è¦å¿«é€Ÿå…¥é—¨çš„åˆå­¦è€…æ¥è¯´ï¼Œå»ºè®®å…ˆç†Ÿæ‚‰æœºå™¨å­¦ä¹ åŸºç¡€æ¦‚å¿µï¼ˆä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Œæœºå™¨å­¦ä¹ ç”¨æ¥å¹²ä»€ä¹ˆï¼Œä»€ä¹ˆæ˜¯æ•°æ®é›†ï¼Œå¦‚ä½•å¯¹æœºå™¨å­¦ä¹ ç®—æ³•è¿›è¡Œè¯„æµ‹ç­‰ï¼‰ï¼Œäº†è§£å‡ ç§å…·ä½“çš„ç»å…¸æœºå™¨å­¦ä¹ ç®—æ³•ã€‚

å¯¹äºåˆå­¦è€…å¯ä»¥å­¦ä¹ ï¼š
* ç½‘è¯¾ï¼šå´æ©è¾¾ æœºå™¨å­¦ä¹ å…¬å¼€è¯¾ï¼›æå®æ¯… æœºå™¨å­¦ä¹ 
* ä¹¦ï¼šæœºå™¨å­¦ä¹ ï¼ˆå‘¨å¿—åï¼Œè¥¿ç“œä¹¦ï¼‰ï¼Œç»Ÿè®¡å­¦ä¹ æ–¹æ³•ï¼ˆæèˆªï¼‰

å¦‚æœæƒ³æ›´æ·±åœ°äº†è§£ï¼š
* ç½‘è¯¾ï¼š[æœºå™¨å­¦ä¹ ç™½æ¿æ¨å¯¼](https://www.bilibili.com/video/BV1aE411o7qd)
* ä¹¦
  * [Pattern Recognition And Machine Learning](https://www.cs.uoi.gr/~arly/courses/ml/tmp/Bishop_book.pdf) (PRML)ï¼Œä»¥è´å¶æ–¯çš„è§†è§’ä»‹ç»æœºå™¨å­¦ä¹ ç®—æ³•ã€‚æœ¬ä¹¦æˆä¹¦äº2012å¹´ï¼Œç”±äºè¿‘å¹´æ¥æ·±åº¦å­¦ä¹ é£é€Ÿå‘å±•ï¼Œè¯¥ä½œè€…åˆç›¸ç»§æ¨å‡ºäº† [Probabilistic Machine Learning: An Introduction](https://github.com/probml/pml-book) å’Œ [Probabilistic Machine Learning: Advanced Topics](https://github.com/probml/pml2-book)
  * Machine Learning: A Probabilistic Prospective (MLAPP)ï¼Œæœºå™¨å­¦ä¹ çš„ç™¾ç§‘å…¨ä¹¦ï¼ŒåŒæ ·åé‡è´å¶æ–¯è§†è§’
  * The Elements of Statistical Learning (ESL)ï¼Œé¢‘ç‡æ´¾

### æ·±åº¦å­¦ä¹ 

æ·±åº¦å­¦ä¹ çš„å‘å±•ä¸ºæˆ‘ä»¬çš„ä¸–ç•Œå¸¦æ¥äº†å·¨å¤§çš„æ”¹å˜ï¼Œ2018çš„å›¾çµå¥–ä¹Ÿé¢ç»™äº†å¯¹æ·±åº¦å­¦ä¹ æœ‰å“è¶Šè´¡çŒ®çš„ Yoshua Bengioã€Yann LeCunã€Geoffrey Hintonã€‚

ä¹¦ï¼šDeep Learningï¼ˆGoodFellow, Bengio, Courvilleï¼‰ï¼Œç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ï¼ˆé‚±é”¡é¹ï¼‰

å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œä»…ä»…äº†è§£æ·±åº¦å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µã€åŸºæœ¬ç®—æ³•æ˜¯ä¸å¤Ÿçš„ï¼Œæ›´åº”å½“åˆ°ä»£ç å½“ä¸­å»è·å¾—æ›´ä¸ºç›´è§‚å’Œæ·±å…¥çš„è®¤è¯†ã€‚å¤§å®¶å¯èƒ½ä¹Ÿå¬è¯´è¿‡ TensorFlowã€PyTorch è¿™æ ·çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç›®å‰å­¦æœ¯ç•Œé€šå¸¸ä½¿ç”¨ PyTorchã€‚

PyTorch å¯¹åˆå­¦è€…ä¹Ÿæä¾›äº†[å¿«é€Ÿå…¥é—¨æŒ‡å—](https://pytorch.org/tutorials/beginner/basics/intro.html)å’Œ [tutorial](https://pytorch.org/tutorials/)ï¼Œå¯¹äº tutorialï¼Œå»ºè®®ä»[ç®€å•çš„å›¾åƒåˆ†ç±»ç®—æ³•](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html#)å­¦èµ·ï¼Œç„¶åå†è¿›ä¸€æ­¥å­¦ä¹ [ç®€å•çš„æ–‡æœ¬åˆ†ç±»](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)ã€[ç®€å•çš„æ–‡æœ¬ç”Ÿæˆ](https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html)ç­‰è‡ªç„¶è¯­è¨€å¤„ç†ç›¸å…³æ•™ç¨‹ã€‚

PyTorch æä¾›äº†éå¸¸è¯¦ç»†çš„[æ–‡æ¡£](https://pytorch.org/docs/stable/index.html)ï¼Œé‡åˆ°ä¸æ˜ç™½çš„å‡½æ•°ã€æ¦‚å¿µéƒ½å¯ä»¥åœ¨æ–‡æ¡£ä¸­è¿›è¡ŒæŸ¥è¯¢å’Œå­¦ä¹ 

### è‡ªç„¶è¯­è¨€å¤„ç†

æˆ‘ä»¬å®éªŒå®¤çš„åç§°ä¸ºè®¡ç®—è¯­è¨€å­¦ç ”ç©¶æ‰€ï¼Œé€šå¸¸æ„ä¹‰ä¸Š[è®¡ç®—è¯­è¨€å­¦](https://zh.wikipedia.org/zh-hans/%E8%AE%A1%E7%AE%97%E8%AF%AD%E8%A8%80%E5%AD%A6)ï¼ˆComputational Linguisticsï¼ŒCLï¼‰å±äºè¯­è¨€å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè€Œ[è‡ªç„¶è¯­è¨€å¤„ç†](https://zh.wikipedia.org/zh/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86)ï¼ˆNatural Language Processingï¼ŒNLPï¼‰ï¼Œåœ¨ç°ä»£æ„ä¹‰ä¸Šä¸¤è€…å¾€å¾€ä¼šæ··ä¸ºä¸€è°ˆã€‚

ä»€ä¹ˆæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†æˆ–è€…è®¡ç®—è¯­è¨€å­¦ï¼Ÿè¿™é‡Œæ‘˜æŠ„ä¸€æ®µ The Association for Computational Linguistics (ACL) çš„ä»‹ç»ï¼š
"Computational linguistics is the scientific study of language from a computational perspective. Computational linguists are interested in providing computational models of various kinds of linguistic phenomena. These models may be "knowledge-based" ("hand-crafted") or "data-driven" ("statistical" or "empirical"). Work in computational linguistics is in some cases motivated from a scientific perspective in that one is trying to provide a computational explanation for a particular linguistic or psycholinguistic phenomenon; and in other cases the motivation may be more purely technological in that one wants to provide a working component of a speech or natural language system. Indeed, the work of computational linguists is incorporated into many working systems today, including speech recognition systems, text-to-speech synthesizers, automated voice response systems, web search engines, text editors, language instruction materials, to name just a few."

NLP åŒ…å«å“ªäº› topic å‘¢ï¼ŸåŒæ ·æ˜¯æ‘˜æŠ„è‡ª 60th Annual Meeting of the Association for Computational Linguistics çš„ Submissions Topicsï¼š
* Computational Social Science and Cultural Analytics
* Dialogue and Interactive Systems
* Discourse and Pragmatics
* Ethics and NLP
* Generation
* Information Extraction
* Information Retrieval and Text Mining
* Interpretability and Analysis of Models for NLP
* Language Grounding to Vision, Robotics and Beyond
* Linguistic Theories, Cognitive Modeling, and Psycholinguistics
* Machine Learning for NLP
* Machine Translation and Multilinguality
* NLP Applications
* Phonology, Morphology, and Word Segmentation
* Question Answering
* Resources and Evaluation
* Semantics: Lexical
* Semantics: Sentence-level Semantics, Textual Inference, and Other Areas
* Sentiment Analysis, Stylistic Analysis, and Argument Mining
* Speech and Multimodality
* Summarization
* Syntax: Tagging, Chunking and Parsing

å¯ä»¥çœ‹åˆ° NLP è¿™ä¸ªè¯­è¨€å­¦å’Œè®¡ç®—æœºç§‘å­¦çš„äº¤å‰å­¦ç§‘å®åœ¨æ˜¯åŒ…å«äº†å¤ªå¤šçš„ç ”ç©¶æ–¹å‘ï¼Œè€Œå…¶ä¸­é™¤äº†æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰ã€æ‘˜è¦ã€QA è¿™äº›å¤§å®¶æ—©æœ‰è€³é—»çš„åº”ç”¨ï¼Œå‰©ä¸‹çš„ç›¸ä¿¡åˆå­¦è€…å¤§å¤šä»æœªå¬è¯´è¿‡ï¼Œå³ä½¿æ˜¯ä¸€ä½ NLP ç ”ç©¶è€…æˆ–ä»ä¸šäººå‘˜ä¹Ÿåªèƒ½å¯¹è¿™ä¸ªåˆ—è¡¨ä¸­çš„æŸä¸€ä¸ªæˆ–å‡ ä¸ªæ–¹é¢æœ‰æ·±å…¥çš„ç ”ç©¶ã€‚

æƒ³è¦å¯¹ NLP æ˜¯ç ”ç©¶ä»€ä¹ˆçš„æœ‰ä¸ªå¤§è‡´çš„äº†è§£ï¼Œé¦–å…ˆæˆ‘ä»¬å¯ä»¥å¿«é€Ÿäº†è§£æ·±åº¦å­¦ä¹ æ—¶ä»£ NLP å‘å±•å†å²ï¼šA Review of the Neural History of Natural Language Processing(https://ruder.io/a-review-of-the-recent-history-of-nlp/)ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥é€šè¿‡è¯¾ç¨‹æˆ–ä¹¦ç±è¿›è¡Œç³»ç»Ÿçš„å­¦ä¹ ï¼š
* ç½‘è¯¾ï¼š
  * [Stanford cs224n](https://web.stanford.edu/class/cs224n/)ï¼ˆå¼ºçƒˆæ¨èï¼Œä¸»è®²äººæ˜¯ç»å¯¹çš„å¤§ç‰› Christopher Manningï¼Œæ­¤è¯¾ç¨‹ä»æ·±åº¦å­¦ä¹ çš„è§’åº¦å‡ºå‘å¯¹ NLP è¿›è¡Œå…¨é¢çš„ä»‹ç»ï¼Œè€Œå…¶ä¸­çš„ talk åˆæ¶‰åŠå­¦æœ¯æœ€å‰æ²¿çš„è¿›å±•ï¼Œå¯è°“å¹¿åº¦ä¸æ·±åº¦ä¿±å…¨ï¼‰
  * CMU CS 11-747
* ä¹¦ï¼š
  * ç»Ÿè®¡è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆå®—æˆåº†ï¼‰æˆä¹¦å¹´ä»£è¾ƒæ—©ï¼Œå…·ä½“æ–¹æ³•ä¸å½“ä¸‹æœ‰è¾ƒå¤§è·ç¦»ï¼Œå¯äº†è§£ NLP åŸºæœ¬é—®é¢˜
  * ç°ä»£è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆé»„æ°‘çƒˆï¼‰ï¼Œå…³æ³¨è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNatural Language Generationï¼ŒNLGï¼‰
  * è‡ªç„¶è¯­è¨€å¤„ç†ï¼šåŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•ï¼ˆè½¦ä¸‡ç¿”ï¼‰ï¼Œå½“ä»Šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPretrained Language Modelï¼ŒPLMï¼‰ä¿¨ç„¶æˆä¸ºäº† NLP ä¸­çš„â€œåŸºç¡€è®¾æ–½â€ï¼ˆFoundation Modelï¼‰ï¼Œâ€œé¢„è®­ç»ƒ-å¾®è°ƒâ€ï¼ˆPretrain & Fine-tuneï¼‰ä¹Ÿæˆä¸ºäº†åº”ç”¨ä¸­çš„åŸºæœ¬èŒƒå¼ï¼Œå› æ­¤æˆ‘ä»¬åŒæ ·éœ€è¦äº†è§£åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•


## æ–‡çŒ®é˜…è¯»

### Google Scholar

[Google Scholar](https://scholar.google.com/) å¯ä»¥ç†è§£ä¸ºå­¦æœ¯ç•Œçš„ Google

### ä¼šè®®è®ºæ–‡

æˆ‘ä»¬ä¸»è¦é˜…è¯»å›½é™…ä¼šè®®è®ºæ–‡ï¼Œç›¸å…³çš„ä¼šè®®æœ‰ï¼š

- è‡ªç„¶è¯­è¨€å¤„ç†ç›¸å…³ä¼šè®®ï¼šACL, EMNLP, NAACL, COLINGï¼ˆæŒ‰å½±å“æ’åºï¼‰
- ML ç†è®ºï¼šICML, NeurIPS, ICLR
- AI åº”ç”¨ï¼šAAAI, IJCAIï¼ˆè¿™ä¸¤ä¸ªä¼šè®®è¿‘å¹´æ¥å½±å“åŠ›ä¸‹é™ï¼‰

å…¶ä¸­ï¼ŒACL ç³»ä¼šè®®æä¾› anthology (https://aclweb.org/anthology/)

### å‰æ²¿è¿›å±•

å¦‚æœæƒ³äº†è§£æŸä¸€ä¸ªé¢†åŸŸçš„å‰æ²¿è¿›å±•ï¼Œé€šå¸¸ä¼šå…³æ³¨ [arXiv](https://arxiv.org/)ï¼ˆé¢„å°æœ¬ï¼‰ï¼Œéƒ¨åˆ†ä½œè€…ä¼šé€‰æ‹©åœ¨å‘è¡¨å‰å°†è®ºæ–‡ä¸Šä¼ è‡³ arXivã€‚arXiv åœ¨å·¥ä½œæ—¥[æ¯æ—¥æ›´æ–°](https://arxiv.org/list/cs.CL/recent)ï¼Œä¾¿äºåŠæ—¶è¿½è¸ªå‰æ²¿åŠ¨æ€


### å·¥å…·

ç»å…¸è®ºæ–‡å¾€å¾€åœ¨ CSDNã€çŸ¥ä¹ç­‰å¹³å°æœ‰ä¸­æ–‡è¯»åæ„Ÿï¼Œå¯ä»¥è¾…åŠ©é˜…è¯»

æ–‡çŒ®åˆ†ç±»æ•´ç†æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ï¼Œå»ºè®®æ ¹æ®ä¸ªäººå–œå¥½é€‰æ‹©è¯¸å¦‚ Zoteroï¼ˆç•Œé¢ç®€æ´ã€è·¨å¹³å°ã€å…è´¹ã€æ‰©å±•ä¸°å¯Œï¼‰, Endnote, Mendeley, Papers ç­‰æ–‡çŒ®ç®¡ç†è½¯ä»¶

åˆå­¦æ—¶åšå¥½è®ºæ–‡ç¬”è®°ï¼Œå¯ä»¥ä½¿ç”¨ Markdownï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ Notionã€Obsidianã€OneNote ç­‰ç¬”è®°è½¯ä»¶





## åŠ¨æ‰‹å®è·µ

### ä»»åŠ¡ä¸€ï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„æ–‡æœ¬åˆ†ç±»

æ–‡æœ¬åˆ†ç±»æ˜¯å…¥é—¨ NLP çš„ä¸€ä¸ªå¥½çš„å¼€å§‹ï¼ŒåŒæ—¶ NLUï¼ˆè‡ªç„¶è¯­è¨€ç†è§£ï¼‰ä»»åŠ¡æœ¬è´¨ä¸Šæ¥è¯´éƒ½å¯ä»¥å½’ç±»ä¸ºæ–‡æœ¬åˆ†ç±»ã€‚è¯·ä½¿ç”¨ CNN æˆ– RNN å®Œæˆ Kaggle ä¸Šä¸€ä¸ªç®€å•çš„æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€‚

ä»»åŠ¡æè¿° & æ•°æ®é›†ï¼šhttps://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/

å‚è€ƒæ–‡çŒ®ï¼š
Convolutional Neural Networks for Sentence Classification (https://aclanthology.org/D14-1181/)
Recurrent Convolutional Neural Networks for Text Classification (https://www.deeplearningitalia.com/wp-content/uploads/2018/03/Recurrent-Convolutional-Neural-Networks-for-Text-Classification.pdf)


### ä»»åŠ¡äºŒï¼šåŸºäº LSTM-CRF çš„å‘½åå®ä½“è¯†åˆ«

åœ¨ NLP ä¸­ï¼Œç»“æ„é¢„æµ‹ï¼ˆStructured Predictionï¼‰æ˜¯æŒ‡è¾“å‡ºç©ºé—´ä¸ºç»“æ„åŒ–å¯¹è±¡çš„ä¸€ç±»ä»»åŠ¡ï¼ŒåŒ…æ‹¬å‘½åå®ä½“è¯†åˆ«ã€å…³ç³»æŠ½å–ã€å…±æŒ‡æ¶ˆè§£ç­‰å­ä»»åŠ¡ï¼Œå‘½åå®ä½“è¯†åˆ«åˆå±äºåºåˆ—æ ‡æ³¨é—®é¢˜ã€‚è¯·å®ç°ç®€å•çš„åŸºäº LSTM-CRF çš„å‘½åå®ä½“è¯†åˆ«

ä»»åŠ¡æè¿°ï¼šhttps://www.clips.uantwerpen.be/conll2003/ner/

æ•°æ®é›†ï¼šCoNLL03 æ–‡ä»¶å¤¹ä¸‹

å‚è€ƒæ–‡çŒ®ï¼š
Neural Architectures for Named Entity Recognition (https://arxiv.org/pdf/1603.01360.pdf)

å»ºè®®ï¼šå¾ªåºæ¸è¿›ï¼Œå…ˆå®ç° LSTM NER æ¨¡å‹ï¼Œå†åœ¨å…¶åŸºç¡€ä¸ŠåŠ ä¸Š CRF å±‚ã€‚


### ä»»åŠ¡ä¸‰ï¼šæ–°é—»æ ‡é¢˜ç”Ÿæˆ

æ‘˜è¦å’Œç¿»è¯‘æ˜¯æ–‡æœ¬ç”Ÿæˆä¸­æ¯”è¾ƒä¸»æµçš„ä¸¤å¤§ä»»åŠ¡ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬é€‰å–ä¸€ä¸ªç®€å•çš„æ–°é—»æ ‡é¢˜ç”Ÿæˆä»»åŠ¡ä½œä¸ºå…¥é—¨é¡¹ç›®ã€‚

æ•°æ®åœ°å€ï¼š http://www.sogou.com/labs/resource/cs.php   å®Œæ•´ç‰ˆ(648M)

å‚è€ƒæ–‡çŒ®ï¼šGenerating News Headlines with Recurrent Neural Networks (https://arxiv.org/abs/1512.01712)

å¯ä»¥å…ˆåŸºäºRNNå®ç°ä¸Šè¿°æ¨¡å‹ï¼Œåœ¨ç®—åŠ›å…è®¸çš„æƒ…å†µä¸‹å†å°è¯•é¢„è®­ç»ƒæ¨¡å‹ã€‚



### ä»»åŠ¡å››ï¼šTransformer

ä»¥ BERTã€GPT ä¸ºä»£è¡¨çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPretrain language modelï¼‰çš„å‡ºç°ä½¿ NLP ç¿»å¼€äº†æ–°çš„ä¸€é¡µï¼Œç›®å‰çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å¤§å¤šåŸºäº Transformer (å¤§åé¼é¼çš„ Attention Is All You Needï¼Œæˆªè‡³2021å¹´10æœˆ21æ—¥ï¼Œcitations è¾¾åˆ°29343)ï¼Œå› æ­¤æƒ³è¦è¿½è¸ªå‰æ²¿ NLP æŠ€æœ¯ï¼Œæˆ‘ä»¬ä¸å¾—ä¸å¯¹ Transformer æœ‰æ·±å…¥çš„ç†è§£ã€‚

è¯·ç»“åˆ Attention Is All You Need åŸè®ºæ–‡ï¼Œè¯»æ‡‚ The Annotated Transformer (http://nlp.seas.harvard.edu/2018/04/03/attention.html)

åŒæ ·å»ºè®®é˜…è¯»ï¼š
äº†è§£ encoder-decoder ç»“æ„ https://huggingface.co/blog/encoder-decoder#encoder-decoder
å¯è§†åŒ– Transformer http://jalammar.github.io/illustrated-transformer/
å…³äº decode https://huggingface.co/blog/how-to-generate

å®è·µï¼šæˆ‘ä»¬åœ¨å®è·µä¸­é€šå¸¸ä¼šä½¿ç”¨ HuggingFaceğŸ¤— çš„ transformers åº“ï¼Œtransformers æ•™ç¨‹ï¼š
https://huggingface.co/course/
æ­¤å¤–é‡åˆ°é—®é¢˜æ—¶æˆ‘ä»¬é€šå¸¸ä¼šæŸ¥çœ‹ transformers çš„æ–‡æ¡£å’Œæºç ï¼šhttps://huggingface.co/transformers/master/index.html



## æœ¬ä»“åº“çš„ä½¿ç”¨è¯´æ˜

1. æœ‰é—®é¢˜å°±æåœ¨issuesé‡Œé¢ï¼ŒåŒç†ä½ ä¹Ÿå¯ä»¥åœ¨issuesé‡Œé¢æ£€ç´¢æ˜¯å¦å·²ç»æœ‰ä½ é‡åˆ°çš„é—®é¢˜ï¼›
2. mainåˆ†æ”¯æ— æ³•ç›´æ¥ä¿®æ”¹ï¼Œæ‰€æœ‰ä¿®æ”¹å‡éœ€è¦é€šè¿‡æäº¤`Pull requests`æ¥å®ç°ï¼Œå¿…é¡»é€‰æ‹©è‡³å°‘ä¸€ä¸ªreviewerï¼Œæ¨èé€‰æ‹©å¤§å¸ˆå…„`Yifan-Song793`æ¥reviewï¼›
3. git commitçš„è§„èŒƒçœ‹[è¿™é‡Œ](https://juejin.cn/post/6844903793033756680)ï¼Œç¦æ­¢ä½¿ç”¨æ„ä¹‰ä¸æ˜çš„testã€addç­‰è¯­å¥ã€‚
