# PKU-TANGENT nlp-tutorial

æœ¬æ•™ç¨‹ä¾›æ–°åŠ å…¥ TANGENT å®éªŒå®¤çš„åŒå­¦å…¥é—¨ NLP ä½¿ç”¨

- [PKU-TANGENT nlp-tutorial](#pku-tangent-nlp-tutorial)
  - [å†™åœ¨å‰é¢](#å†™åœ¨å‰é¢)
  - [åŸºç¡€çŸ¥è¯†](#åŸºç¡€çŸ¥è¯†)
    - [æœºå™¨å­¦ä¹ ](#æœºå™¨å­¦ä¹ )
    - [æ·±åº¦å­¦ä¹ ](#æ·±åº¦å­¦ä¹ )
    - [è‡ªç„¶è¯­è¨€å¤„ç†](#è‡ªç„¶è¯­è¨€å¤„ç†)
  - [æ–‡çŒ®é˜…è¯»](#æ–‡çŒ®é˜…è¯»)
    - [Google Scholar](#google-scholar)
    - [ä¼šè®®è®ºæ–‡](#ä¼šè®®è®ºæ–‡)
    - [å‰æ²¿è¿›å±•](#å‰æ²¿è¿›å±•)
    - [å·¥å…·](#å·¥å…·)
    - [å¼€æºä»£ç ](#å¼€æºä»£ç )
  - [åŠ¨æ‰‹å®è·µ](#åŠ¨æ‰‹å®è·µ)
    - [å†™åœ¨å‰é¢](#å†™åœ¨å‰é¢-1)
    - [ä»»åŠ¡ä¸€ï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„æ–‡æœ¬åˆ†ç±»](#ä»»åŠ¡ä¸€åŸºäºæ·±åº¦å­¦ä¹ çš„æ–‡æœ¬åˆ†ç±»)
    - [ä»»åŠ¡äºŒï¼šåŸºäº LSTM-CRF çš„å‘½åå®ä½“è¯†åˆ«](#ä»»åŠ¡äºŒåŸºäº-lstm-crf-çš„å‘½åå®ä½“è¯†åˆ«)
    - [ä»»åŠ¡ä¸‰ï¼šNeural Machine Translation (NMT)](#ä»»åŠ¡ä¸‰neural-machine-translation-nmt)
    - [ä»»åŠ¡å››ï¼šTransformer & PLM](#ä»»åŠ¡å››transformer--plm)
      - [åŸºç¡€çŸ¥è¯†](#åŸºç¡€çŸ¥è¯†-1)
      - [Huggingface Transformers](#huggingface-transformers)
      - [Huggingface Ecosystem](#huggingface-ecosystem)
      - [åŸºäºHuggingface Trainerçš„åˆ†ç±»ä»»åŠ¡](#åŸºäºhuggingface-trainerçš„åˆ†ç±»ä»»åŠ¡)
  - [æœ¬ä»“åº“çš„ä½¿ç”¨è¯´æ˜](#æœ¬ä»“åº“çš„ä½¿ç”¨è¯´æ˜)

## å†™åœ¨å‰é¢

ç›¸ä¿¡å¤§å®¶ç»è¿‡å‡ å¹´çš„å­¦ä¹ ï¼Œå·²ç»æ‹¥æœ‰äº†ä»¥ä¸‹çš„æŠ€èƒ½ï¼š
1. ä¼˜ç§€çš„ä¿¡æ¯æ£€ç´¢èƒ½åŠ›ï¼Œæ— è®ºæ˜¯åœ¨è®ºæ–‡é˜…è¯»ã€å†™ä»£ç ã€ä½¿ç”¨æœåŠ¡å™¨ã€å†™è®ºæ–‡ç­‰è¿‡ç¨‹ä¸­éƒ½æœ‰å¯èƒ½é‡åˆ°å„ç§å„æ ·çš„é—®é¢˜ï¼Œåœ¨è¯¢é—®ä»–äººä¹‹å‰ï¼Œè¯·å–„ç”¨æœç´¢
2. ä¼˜ç§€çš„è‹±æ–‡é˜…è¯»èƒ½åŠ›å’ŒåŸºæœ¬çš„è‹±è¯­å†™ä½œèƒ½åŠ›
3. è‰¯å¥½çš„ç¼–ç¨‹èƒ½åŠ›ï¼Œåœ¨ NLP ç›¸å…³ç ”ç©¶ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šä½¿ç”¨ Pythonï¼Œå¦‚æœä½ ä¹‹å‰åªå­¦è¿‡ C æˆ–è€… C++ï¼Œé‚£ä¹ˆå…¥é—¨ Python å¯¹äºä½ æ¥è¯´å°†ä¸æ˜¯ä¸€ä»¶éš¾äº‹ã€‚
æˆ‘ä»¬ä¸€èˆ¬ä½¿ç”¨ Anacondaï¼ˆMinicondaï¼‰æ¥ç®¡ç†ä¸ªäººç”µè„‘ä¹ƒè‡³ Linux æœåŠ¡å™¨ä¸Šçš„ Python ç¯å¢ƒï¼Œè¯·æå‰å®‰è£…å¹¶å­¦ä¹  conda çš„ä½¿ç”¨ã€‚
æ­¤å¤–åœ¨ç§‘ç ”ä¸­æˆ‘ä»¬ç»å¸¸ä¼šä¸ä»–äººåˆä½œï¼Œå› æ­¤è¯·ä¿æŒè‰¯å¥½çš„ä»£ç ä¹ æƒ¯ï¼Œå¦‚æœä½ ä¸äº†è§£ä»£ç è§„èŒƒï¼Œè¯·å‚è€ƒ [Google çš„ Python ä»£ç è§„èŒƒ](https://zh-google-styleguide.readthedocs.io/en/latest/google-python-styleguide/python_style_rules/)
4. æ•°å­¦åŸºç¡€ï¼Œä½œä¸ºä¸€åç†å·¥ç§‘çš„å­¦ç”Ÿï¼Œä½ åº”è¯¥å·²ç»å­¦è¿‡é«˜ç­‰æ•°å­¦ï¼ˆæ•°å­¦åˆ†æï¼‰ã€çº¿æ€§ä»£æ•°ï¼ˆé«˜ç­‰ä»£æ•°ï¼‰ã€æ¦‚ç‡è®ºä¸ç»Ÿè®¡ç­‰åŸºç¡€æ•°å­¦è¯¾ç¨‹ï¼Œåœ¨å…¥é—¨é˜¶æ®µæˆ‘ä»¬æ¶‰åŠåˆ°çš„æ•°å­¦çŸ¥è¯†è¾ƒä¸ºç®€å•ï¼Œä½†æ˜¯æ‰å®çš„æ•°ç†åŸºç¡€ä¼šæ”¯æ’‘ä½ èµ°å¾—æ›´æ·±æ›´è¿œã€‚
5. æœ€å¥½æ‹¥æœ‰ Linux ç³»ç»Ÿä½¿ç”¨ç»éªŒï¼Œç›®å‰æ˜¯æ·±åº¦å­¦ä¹ çš„æ—¶ä»£ï¼Œå¯¹äºè‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸï¼Œåˆæ˜¯å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„æ—¶ä»£ï¼Œä¸ªäººç”µè„‘æ— æ³•æ”¯æ’‘å¤§æ¨¡å‹çš„è®­ç»ƒï¼Œæˆ‘ä»¬å°†ä½¿ç”¨ Linux æœåŠ¡å™¨è¿›è¡Œ Coding å’Œå®éªŒï¼Œæå‰äº†è§£å·¥ä½œæµç¨‹ä¼šå¤§å¤§æé«˜æ•ˆç‡ã€‚
æœ¬æ•™ç¨‹[åŠ¨æ‰‹å®è·µ](#åŠ¨æ‰‹å®è·µ)éƒ¨åˆ†åŸºäº CNN å’Œ RNNï¼ˆLSTMï¼‰çš„æ¨¡å‹ç†è®ºä¸Šå¯ä»¥åœ¨ä¸ªäººç”µè„‘ä¸Šè¿è¡Œï¼Œå¦‚éœ€ GPU èµ„æºï¼Œè¯·è”ç³»å®éªŒå®¤æœåŠ¡å™¨ç®¡ç†å‘˜ã€‚


## åŸºç¡€çŸ¥è¯†

æˆ‘ä»¬é»˜è®¤å¤§å®¶å·²ç»å®Œæˆäº†è®¡ç®—æœºä¸“ä¸šæœ¬ç§‘ä¸€å¹´çº§å’ŒäºŒå¹´çº§çš„ç›¸å…³è¯¾ç¨‹ï¼Œæ‹¥æœ‰ä¸€å®šçš„æ•°å­¦å’Œç¼–ç¨‹åŸºç¡€

### æœºå™¨å­¦ä¹ 

è™½ç„¶ç›®å‰æ˜¯æ·±åº¦å­¦ä¹ çš„æ—¶ä»£ï¼Œæˆ‘ä»¬ä¹Ÿå¾ˆå°‘ä½¿ç”¨ä¼ ç»Ÿæœºå™¨å­¦ä¹ çš„ç®—æ³•æ¥è§£å†³é—®é¢˜ï¼Œä½†æ˜¯ä¸€æ–¹é¢ä¸€äº›åŸºç¡€æ¦‚å¿µä»ç„¶æ˜¯ç›¸é€šçš„ï¼Œå¦ä¸€æ–¹é¢ç»å…¸æœºå™¨å­¦ä¹ ç®—æ³•çš„æ€æƒ³ï¼Œå¦‚ EMã€LDA ç­‰ï¼Œåœ¨æ·±åº¦å­¦ä¹ æ—¶ä»£å¾€å¾€èƒ½å¤Ÿå†ä¹…å¼¥æ–°ï¼Œä»¥å¦ä¸€ç§æ–¹å¼ç„•å‘å‡ºæ–°çš„å…‰å½©ã€‚
å¯¹äºæƒ³è¦å¿«é€Ÿå…¥é—¨çš„åˆå­¦è€…æ¥è¯´ï¼Œå»ºè®®å…ˆç†Ÿæ‚‰æœºå™¨å­¦ä¹ åŸºç¡€æ¦‚å¿µï¼ˆä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Œæœºå™¨å­¦ä¹ ç”¨æ¥å¹²ä»€ä¹ˆï¼Œä»€ä¹ˆæ˜¯æ•°æ®é›†ï¼Œå¦‚ä½•å¯¹æœºå™¨å­¦ä¹ ç®—æ³•è¿›è¡Œè¯„æµ‹ç­‰ï¼‰ï¼Œäº†è§£å‡ ç§å…·ä½“çš„ç»å…¸æœºå™¨å­¦ä¹ ç®—æ³•ã€‚

å¯¹äºåˆå­¦è€…å¯ä»¥å­¦ä¹ ï¼š
* ç½‘è¯¾ï¼šå´æ©è¾¾ æœºå™¨å­¦ä¹ å…¬å¼€è¯¾ï¼›æå®æ¯… æœºå™¨å­¦ä¹ 
* ä¹¦ï¼šæœºå™¨å­¦ä¹ ï¼ˆå‘¨å¿—åï¼Œè¥¿ç“œä¹¦ï¼‰ï¼Œç»Ÿè®¡å­¦ä¹ æ–¹æ³•ï¼ˆæèˆªï¼‰

å¦‚æœæƒ³æ›´æ·±åœ°äº†è§£ï¼š
* ç½‘è¯¾ï¼š[æœºå™¨å­¦ä¹ ç™½æ¿æ¨å¯¼](https://www.bilibili.com/video/BV1aE411o7qd)
* ä¹¦
  * [Pattern Recognition And Machine Learning](https://www.cs.uoi.gr/~arly/courses/ml/tmp/Bishop_book.pdf) (PRML)ï¼Œä»¥è´å¶æ–¯çš„è§†è§’ä»‹ç»æœºå™¨å­¦ä¹ ç®—æ³•ã€‚
  * Machine Learning: A Probabilistic Prospective (MLAPP)ï¼Œæœºå™¨å­¦ä¹ çš„ç™¾ç§‘å…¨ä¹¦ï¼ŒåŒæ ·åé‡è´å¶æ–¯è§†è§’ã€‚åŸä¹¦æˆä¹¦äº2012å¹´ï¼Œè¯¥ä½œè€…åˆç›¸ç»§æ¨å‡ºäº† [Probabilistic Machine Learning: An Introduction](https://github.com/probml/pml-book) å’Œ [Probabilistic Machine Learning: Advanced Topics](https://github.com/probml/pml2-book)
  * The Elements of Statistical Learning (ESL)ï¼Œé¢‘ç‡æ´¾

### æ·±åº¦å­¦ä¹ 

æ·±åº¦å­¦ä¹ çš„å‘å±•ä¸ºæˆ‘ä»¬çš„ä¸–ç•Œå¸¦æ¥äº†å·¨å¤§çš„æ”¹å˜ï¼Œ2018çš„å›¾çµå¥–ä¹Ÿé¢ç»™äº†å¯¹æ·±åº¦å­¦ä¹ æœ‰å“è¶Šè´¡çŒ®çš„ Yoshua Bengioã€Yann LeCunã€Geoffrey Hintonã€‚

ä¹¦ï¼šDeep Learningï¼ˆGoodFellow, Bengio, Courvilleï¼‰ï¼Œç¥ç»ç½‘ç»œä¸æ·±åº¦å­¦ä¹ ï¼ˆé‚±é”¡é¹ï¼‰

å¯¹äºåˆå­¦è€…æ¥è¯´ï¼Œä»…ä»…äº†è§£æ·±åº¦å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µã€åŸºæœ¬ç®—æ³•æ˜¯ä¸å¤Ÿçš„ï¼Œæ›´åº”å½“åˆ°ä»£ç å½“ä¸­å»è·å¾—æ›´ä¸ºç›´è§‚å’Œæ·±å…¥çš„è®¤è¯†ã€‚å¤§å®¶å¯èƒ½ä¹Ÿå¬è¯´è¿‡ TensorFlowã€PyTorch è¿™æ ·çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œç›®å‰å­¦æœ¯ç•Œé€šå¸¸ä½¿ç”¨ PyTorchã€‚

PyTorch å¯¹åˆå­¦è€…ä¹Ÿæä¾›äº†[å¿«é€Ÿå…¥é—¨æŒ‡å—](https://pytorch.org/tutorials/beginner/basics/intro.html)å’Œ [tutorial](https://pytorch.org/tutorials/)ï¼Œå¯¹äº tutorialï¼Œå»ºè®®ä»[ç®€å•çš„å›¾åƒåˆ†ç±»ç®—æ³•](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html#)å­¦èµ·ï¼Œç„¶åå†è¿›ä¸€æ­¥å­¦ä¹ [ç®€å•çš„æ–‡æœ¬åˆ†ç±»](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html)ã€[ç®€å•çš„æ–‡æœ¬ç”Ÿæˆ](https://pytorch.org/tutorials/intermediate/char_rnn_generation_tutorial.html)ç­‰è‡ªç„¶è¯­è¨€å¤„ç†ç›¸å…³æ•™ç¨‹ã€‚

PyTorch æä¾›äº†éå¸¸è¯¦ç»†çš„[æ–‡æ¡£](https://pytorch.org/docs/stable/index.html)ï¼Œé‡åˆ°ä¸æ˜ç™½çš„å‡½æ•°ã€æ¦‚å¿µéƒ½å¯ä»¥åœ¨æ–‡æ¡£ä¸­è¿›è¡ŒæŸ¥è¯¢å’Œå­¦ä¹ 

### è‡ªç„¶è¯­è¨€å¤„ç†

æˆ‘ä»¬å®éªŒå®¤çš„åç§°ä¸ºè®¡ç®—è¯­è¨€å­¦ç ”ç©¶æ‰€ï¼Œé€šå¸¸æ„ä¹‰ä¸Š[è®¡ç®—è¯­è¨€å­¦](https://zh.wikipedia.org/zh-hans/%E8%AE%A1%E7%AE%97%E8%AF%AD%E8%A8%80%E5%AD%A6)ï¼ˆComputational Linguisticsï¼ŒCLï¼‰å±äºè¯­è¨€å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œè€Œ[è‡ªç„¶è¯­è¨€å¤„ç†](https://zh.wikipedia.org/zh/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86)ï¼ˆNatural Language Processingï¼ŒNLPï¼‰ï¼Œåœ¨ç°ä»£æ„ä¹‰ä¸Šä¸¤è€…å¾€å¾€ä¼šæ··ä¸ºä¸€è°ˆã€‚

ä»€ä¹ˆæ˜¯è‡ªç„¶è¯­è¨€å¤„ç†æˆ–è€…è®¡ç®—è¯­è¨€å­¦ï¼Ÿè¿™é‡Œæ‘˜æŠ„ä¸€æ®µ The Association for Computational Linguistics (ACL) çš„ä»‹ç»ï¼š
"Computational linguistics is the scientific study of language from a computational perspective. Computational linguists are interested in providing computational models of various kinds of linguistic phenomena. These models may be "knowledge-based" ("hand-crafted") or "data-driven" ("statistical" or "empirical"). Work in computational linguistics is in some cases motivated from a scientific perspective in that one is trying to provide a computational explanation for a particular linguistic or psycholinguistic phenomenon; and in other cases the motivation may be more purely technological in that one wants to provide a working component of a speech or natural language system. Indeed, the work of computational linguists is incorporated into many working systems today, including speech recognition systems, text-to-speech synthesizers, automated voice response systems, web search engines, text editors, language instruction materials, to name just a few."

NLP åŒ…å«å“ªäº› topic å‘¢ï¼ŸåŒæ ·æ˜¯æ‘˜æŠ„è‡ª 60th Annual Meeting of the Association for Computational Linguistics çš„ Submissions Topicsï¼š
* Computational Social Science and Cultural Analytics
* Dialogue and Interactive Systems
* Discourse and Pragmatics
* Ethics and NLP
* Generation
* Information Extraction
* Information Retrieval and Text Mining
* Interpretability and Analysis of Models for NLP
* Language Grounding to Vision, Robotics and Beyond
* Linguistic Theories, Cognitive Modeling, and Psycholinguistics
* Machine Learning for NLP
* Machine Translation and Multilinguality
* NLP Applications
* Phonology, Morphology, and Word Segmentation
* Question Answering
* Resources and Evaluation
* Semantics: Lexical
* Semantics: Sentence-level Semantics, Textual Inference, and Other Areas
* Sentiment Analysis, Stylistic Analysis, and Argument Mining
* Speech and Multimodality
* Summarization
* Syntax: Tagging, Chunking and Parsing

å¯ä»¥çœ‹åˆ° NLP è¿™ä¸ªè¯­è¨€å­¦å’Œè®¡ç®—æœºç§‘å­¦çš„äº¤å‰å­¦ç§‘å®åœ¨æ˜¯åŒ…å«äº†å¤ªå¤šçš„ç ”ç©¶æ–¹å‘ï¼Œè€Œå…¶ä¸­é™¤äº†æœºå™¨ç¿»è¯‘ï¼ˆMTï¼‰ã€æ‘˜è¦ã€QA è¿™äº›å¤§å®¶æ—©æœ‰è€³é—»çš„åº”ç”¨ï¼Œå‰©ä¸‹çš„ç›¸ä¿¡åˆå­¦è€…å¤§å¤šä»æœªå¬è¯´è¿‡ï¼Œå³ä½¿æ˜¯ä¸€ä½ NLP ç ”ç©¶è€…æˆ–ä»ä¸šäººå‘˜ä¹Ÿåªèƒ½å¯¹è¿™ä¸ªåˆ—è¡¨ä¸­çš„æŸä¸€ä¸ªæˆ–å‡ ä¸ªæ–¹é¢æœ‰æ·±å…¥çš„ç ”ç©¶ã€‚


æƒ³è¦å¯¹ NLP æ˜¯ç ”ç©¶ä»€ä¹ˆçš„æœ‰ä¸ªå¤§è‡´çš„äº†è§£ï¼Œé¦–å…ˆæˆ‘ä»¬å¯ä»¥å¿«é€Ÿäº†è§£æ·±åº¦å­¦ä¹ æ—¶ä»£ NLP å‘å±•å†å²ï¼šA Review of the Neural History of Natural Language Processing(https://ruder.io/a-review-of-the-recent-history-of-nlp/ )ï¼Œç„¶åæˆ‘ä»¬å¯ä»¥é€šè¿‡è¯¾ç¨‹æˆ–ä¹¦ç±è¿›è¡Œç³»ç»Ÿçš„å­¦ä¹ ï¼š

* ç½‘è¯¾ï¼š
  * [Stanford cs224n](https://web.stanford.edu/class/cs224n/)ï¼ˆå¼ºçƒˆæ¨èï¼Œä¸»è®²äººæ˜¯ç»å¯¹çš„å¤§ç‰› Christopher Manningï¼Œæ­¤è¯¾ç¨‹ä»æ·±åº¦å­¦ä¹ çš„è§’åº¦å‡ºå‘å¯¹ NLP è¿›è¡Œå…¨é¢çš„ä»‹ç»ï¼Œè€Œå…¶ä¸­çš„ talk åˆæ¶‰åŠå­¦æœ¯æœ€å‰æ²¿çš„è¿›å±•ï¼Œå¯è°“å¹¿åº¦ä¸æ·±åº¦ä¿±å…¨ï¼‰
  * CMU CS 11-747
* ä¹¦ï¼š
  * ç»Ÿè®¡è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆå®—æˆåº†ï¼‰æˆä¹¦å¹´ä»£è¾ƒæ—©ï¼Œå…·ä½“æ–¹æ³•ä¸å½“ä¸‹æœ‰è¾ƒå¤§è·ç¦»ï¼Œå¯äº†è§£ NLP åŸºæœ¬é—®é¢˜
  * ç°ä»£è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆé»„æ°‘çƒˆï¼‰ï¼Œå…³æ³¨è‡ªç„¶è¯­è¨€ç”Ÿæˆï¼ˆNatural Language Generationï¼ŒNLGï¼‰
  * è‡ªç„¶è¯­è¨€å¤„ç†ï¼šåŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•ï¼ˆè½¦ä¸‡ç¿”ï¼‰ï¼Œå½“ä»Šé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPretrained Language Modelï¼ŒPLMï¼‰ä¿¨ç„¶æˆä¸ºäº† NLP ä¸­çš„â€œåŸºç¡€è®¾æ–½â€ï¼ˆFoundation Modelï¼‰ï¼Œâ€œé¢„è®­ç»ƒ-å¾®è°ƒâ€ï¼ˆPretrain & Fine-tuneï¼‰ä¹Ÿæˆä¸ºäº†åº”ç”¨ä¸­çš„åŸºæœ¬èŒƒå¼ï¼Œå› æ­¤æˆ‘ä»¬åŒæ ·éœ€è¦äº†è§£åŸºäºé¢„è®­ç»ƒæ¨¡å‹çš„æ–¹æ³•


## æ–‡çŒ®é˜…è¯»

### Google Scholar

[Google Scholar](https://scholar.google.com/) å¯ä»¥ç†è§£ä¸ºå­¦æœ¯ç•Œçš„ Google

### ä¼šè®®è®ºæ–‡

æˆ‘ä»¬ä¸»è¦é˜…è¯»å›½é™…ä¼šè®®è®ºæ–‡ï¼Œç›¸å…³çš„ä¼šè®®æœ‰ï¼š

- è‡ªç„¶è¯­è¨€å¤„ç†ç›¸å…³ä¼šè®®ï¼šACL, EMNLP, NAACL, COLINGï¼ˆæŒ‰å½±å“åŠ›æ’åºï¼‰
- ML ç†è®ºï¼šICML, NeurIPS, ICLR
- AI åº”ç”¨ï¼šAAAI, IJCAIï¼ˆè¿™ä¸¤ä¸ªä¼šè®®è¿‘å¹´æ¥å½±å“åŠ›ä¸‹é™ï¼‰

å…¶ä¸­ï¼ŒACL ç³»ä¼šè®®æä¾› anthology (https://aclweb.org/anthology/)ï¼Œå¯ä»¥æ–¹ä¾¿åœ°æŸ¥æ‰¾å†å¹´è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„è®ºæ–‡

### å‰æ²¿è¿›å±•

å¦‚æœæƒ³äº†è§£æŸä¸€ä¸ªé¢†åŸŸçš„å‰æ²¿è¿›å±•ï¼Œé€šå¸¸ä¼šå…³æ³¨ [arXiv](https://arxiv.org/)ï¼ˆé¢„å°æœ¬ï¼‰ï¼Œéƒ¨åˆ†ä½œè€…ä¼šé€‰æ‹©åœ¨å‘è¡¨å‰å°†è®ºæ–‡ä¸Šä¼ è‡³ arXivã€‚arXiv åœ¨å·¥ä½œæ—¥[æ¯æ—¥æ›´æ–°](https://arxiv.org/list/cs.CL/recent)ï¼Œä¾¿äºåŠæ—¶è¿½è¸ªå‰æ²¿åŠ¨æ€


### å·¥å…·

ç»å…¸è®ºæ–‡å¾€å¾€åœ¨ CSDNã€çŸ¥ä¹ç­‰å¹³å°æœ‰ä¸­æ–‡è¯»åæ„Ÿï¼Œå¯ä»¥è¾…åŠ©é˜…è¯»

æ–‡çŒ®åˆ†ç±»æ•´ç†æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ï¼Œå»ºè®®æ ¹æ®ä¸ªäººå–œå¥½é€‰æ‹©è¯¸å¦‚ Zoteroï¼ˆç•Œé¢ç®€æ´ã€è·¨å¹³å°ã€å…è´¹ã€æ‰©å±•ä¸°å¯Œï¼‰, Endnote, Mendeley, Papers ç­‰æ–‡çŒ®ç®¡ç†è½¯ä»¶

åˆå­¦æ—¶åšå¥½è®ºæ–‡ç¬”è®°ï¼Œå¯ä»¥ä½¿ç”¨ Markdownï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨ Notionã€Obsidianã€OneNote ç­‰ç¬”è®°è½¯ä»¶

### å¼€æºä»£ç 

éšç€æ—¶ä»£çš„è¿›æ­¥ï¼Œè¶Šæ¥è¶Šå¤šçš„å·¥ä½œä¼šå¼€æºä»£ç ï¼Œä¾¿äºå…¶ä»–ç ”ç©¶è€… follow å’Œå¤ç°å®éªŒã€‚å¼€æºé“¾æ¥ï¼ˆGitHub é“¾æ¥ï¼‰ä¸€èˆ¬ä¼šåœ¨è®ºæ–‡ä¸­å‡ºç°ï¼Œå¯ä»¥åœ¨è®ºæ–‡ä¸­ `Ctrl-F` æœç´¢ â€œgithubâ€ å¿«é€Ÿå®šä½å¼€æºé“¾æ¥ã€‚

Git å’Œ GitHub åŸºæœ¬æ“ä½œè¯·è‡ªè¡Œå­¦ä¹ ã€‚å¦‚æœåœ¨å¤ç°è®ºæ–‡çš„è¿‡ç¨‹ä¸­å‡ºç°é—®é¢˜ï¼Œå¯ä»¥åœ¨å¼€æºä»£ç çš„ Issues ä¸­æé—®ï¼Œåœ¨å¤ç°ä¹‹å‰ä¹Ÿåº”å½“å…ˆæŸ¥çœ‹ Issuesï¼Œå…å¾—è¸©åˆ«äººè¸©è¿‡çš„å‘ã€‚


## åŠ¨æ‰‹å®è·µ

ä½œä¸ºè®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼ŒNLP åŒæ ·ç¦»ä¸å¼€ codingï¼Œè¯·æœ‰å¿—åŠ å…¥ TANGENT çš„åŒå­¦å®Œæˆä»¥ä¸‹ç»ƒä¹ ä»»åŠ¡ã€‚

### å†™åœ¨å‰é¢

åœ¨å®Œæˆè¿™äº›ä»»åŠ¡ä¹‹å‰ï¼Œè¿˜æ˜¯éœ€è¦ä¸€äº›è¯´æ˜ã€‚

ä¸€ä¸ªæ·±åº¦å­¦ä¹ é¡¹ç›®çš„æµç¨‹é€šå¸¸æ˜¯è¿™æ ·çš„ï¼š
1. æ•°æ®è¯»å–å’Œé¢„å¤„ç†ï¼Œå¾—åˆ° Dataset å’Œ DataLoader
2. æ„å»º Modelã€Optimizer
3. ä½¿ç”¨éšæœºæ¢¯åº¦ä¸‹é™è¿­ä»£ä¼˜åŒ–æ¨¡å‹å‚æ•°
4. è®¾ç½® Metricï¼Œå¯¹æ¨¡å‹è¿›è¡Œè¯„æµ‹

é€šå¸¸æˆ‘ä»¬ä¹Ÿä¼šæŒ‰ç…§ä¸Šè¿°æµç¨‹å’Œæµç¨‹ä¸­å‡ºç°çš„å„ä¸ªæ¨¡å—ç»„ç»‡é¡¹ç›®æ–‡ä»¶ï¼Œä¸€ä¸ªé¡¹ç›®å¾€å¾€ä¼šåŒ…å«è¿™äº›æ–‡ä»¶ï¼šä¸»å‡½æ•°ï¼ˆå…¥å£ï¼Œè´Ÿè´£ä»¥ä¸Šæµç¨‹çš„æ§åˆ¶ï¼‰ï¼Œæ•°æ®è¯»å–å’Œé¢„å¤„ç†ï¼Œæ¨¡å‹ï¼ŒMetricã€‚

æˆ‘ä»¬é’ˆå¯¹ä»»åŠ¡äºŒï¼Œç»™å‡ºäº†ä¸€ä¸ª ChineseNER å®Œæ•´é¡¹ç›®çš„[æºä»£ç ](https://github.com/PKU-TANGENT/nlp-tutorial/tree/main/ChineseNER)ã€‚

éœ€æ³¨æ„ï¼Œä¸‹é¢éƒ¨åˆ†ä»»åŠ¡å‚è€ƒä»£ç æ˜¯ä»¥ Notebook çš„å½¢å¼ç»„ç»‡çš„ï¼Œåœ¨å®Œæˆä»»åŠ¡æ—¶ï¼Œè¯·å‚è€ƒ ChineseNER é‡æ–°ç»„ç»‡ä»£ç ã€‚

æ­¤å¤–è¿˜æœ‰ç§‘ç ”å·¥ä½œè€…çš„è€å¤§éš¾é—®é¢˜ï¼šç¯å¢ƒé…ç½®ï¼Œåœ¨è¿›è¡Œä»¥ä¸‹ä»»åŠ¡ä¹‹å‰ï¼Œè¯·åœ¨ä¸ªäººç”µè„‘æˆ–æœåŠ¡å™¨é…ç½®å¥½ Anaconda æˆ– minicondaï¼Œæ–°å»ºç¯å¢ƒï¼Œå¹¶å®‰è£…æœ€æ–°ç‰ˆ PyTorch

### ä»»åŠ¡ä¸€ï¼šåŸºäºæ·±åº¦å­¦ä¹ çš„æ–‡æœ¬åˆ†ç±»

æ–‡æœ¬åˆ†ç±»æ˜¯å…¥é—¨ NLP çš„ä¸€ä¸ªå¥½çš„å¼€å§‹ï¼ŒåŒæ—¶ NLUï¼ˆè‡ªç„¶è¯­è¨€ç†è§£ï¼‰ä»»åŠ¡æœ¬è´¨ä¸Šæ¥è¯´éƒ½å¯ä»¥å½’ç±»ä¸ºæ–‡æœ¬åˆ†ç±»ã€‚è¯·ä½¿ç”¨ CNN æˆ– RNNï¼ˆLSTMï¼‰ å®Œæˆ Kaggle ä¸Šä¸€ä¸ªç®€å•çš„æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ã€‚

ä»»åŠ¡æè¿° & æ•°æ®é›†ï¼šhttps://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/

Kaggle é‡Œä¹Ÿæœ‰ä¸€äº›[ä»£ç ](https://www.kaggle.com/competitions/sentiment-analysis-on-movie-reviews/code)å¯ä»¥å‚è€ƒï¼Œå¦‚ï¼š[LSTM å®ç°](https://www.kaggle.com/code/hanjoonchoe/movie-sentimental-analysis-lstm-pytorch)

å‚è€ƒæ–‡çŒ®ï¼š
Convolutional Neural Networks for Sentence Classification (https://aclanthology.org/D14-1181/)
Recurrent Convolutional Neural Networks for Text Classification (https://www.deeplearningitalia.com/wp-content/uploads/2018/03/Recurrent-Convolutional-Neural-Networks-for-Text-Classification.pdf)


### ä»»åŠ¡äºŒï¼šåŸºäº LSTM-CRF çš„å‘½åå®ä½“è¯†åˆ«

åœ¨ NLP ä¸­ï¼Œç»“æ„é¢„æµ‹ï¼ˆStructured Predictionï¼‰æ˜¯æŒ‡è¾“å‡ºç©ºé—´ä¸ºç»“æ„åŒ–å¯¹è±¡çš„ä¸€ç±»ä»»åŠ¡ï¼ŒåŒ…æ‹¬å‘½åå®ä½“è¯†åˆ«ã€å…³ç³»æŠ½å–ã€å…±æŒ‡æ¶ˆè§£ç­‰å­ä»»åŠ¡ï¼Œå‘½åå®ä½“è¯†åˆ«åˆå±äºåºåˆ—æ ‡æ³¨é—®é¢˜ã€‚è¯·å®ç°ç®€å•çš„åŸºäº LSTM-CRF çš„å‘½åå®ä½“è¯†åˆ«

ä»»åŠ¡æè¿°ï¼šhttps://www.clips.uantwerpen.be/conll2003/ner/

æ•°æ®é›†ï¼šæœ¬ä»“åº“ [CoNLL03](https://github.com/PKU-TANGENT/nlp-tutorial/tree/main/CoNLL03) æ–‡ä»¶å¤¹ä¸‹

å‚è€ƒæ–‡çŒ®ï¼š
Neural Architectures for Named Entity Recognition (https://arxiv.org/pdf/1603.01360.pdf)

ä¸ºäº†ç®€åŒ–ä»»åŠ¡éš¾åº¦ï¼Œæˆ‘ä»¬ç»™å‡ºäº†åŸºäº LSTM çš„ä¸­æ–‡å‘½åå®ä½“è¯†åˆ«çš„[ä»£ç ](https://github.com/PKU-TANGENT/nlp-tutorial/tree/main/ChineseNER)ï¼Œé…ç½®å¥½ PyTorch ç¯å¢ƒåï¼Œä» `ChineseNER/train.py` å³å¯ç›´æ¥è¿è¡Œã€‚å¯å‚è€ƒè¯¥ä»£ç å°†å…¶è¿ç§»è‡³ CoNLL03 è‹±æ–‡æ•°æ®é›†ä¸Šï¼Œè¿›è¡Œå®éªŒè§‚å¯Ÿåˆæ­¥ç»“æœï¼Œåç»­å†å¢åŠ  CRF å±‚ã€‚


### ä»»åŠ¡ä¸‰ï¼šNeural Machine Translation (NMT)

æ‘˜è¦å’Œç¿»è¯‘æ˜¯æ–‡æœ¬ç”Ÿæˆä¸­æ¯”è¾ƒä¸»æµçš„ä¸¤å¤§ä»»åŠ¡ï¼Œåœ¨è¿™é‡Œæˆ‘ä»¬é€‰å– PyTorch tutorial ä¸­çš„æ–‡æœ¬ç¿»è¯‘ä½œä¸ºå…¥é—¨é¡¹ç›®ã€‚

è¯·æŒ‰ç…§ [PyTorch æ–‡æœ¬ç¿»è¯‘æ•™ç¨‹](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)ï¼Œä¸€æ­¥æ­¥å®ç°ä¸€ä¸ªç®€å•çš„æ–‡æœ¬ç¿»è¯‘æ¨¡å‹ï¼Œæ³¨æ„è¯·å‚è€ƒ ChineseNER çš„ç»„ç»‡æ–¹å¼é‡æ„ä»£ç ã€‚

ç”Ÿæˆä»»åŠ¡æ¶‰åŠåˆ°çš„ç»†èŠ‚è¾ƒå¤šï¼Œå¦‚ encoder-decoderï¼Œteacher forcingï¼Œbeam search ç­‰ï¼Œtutorial ä¸­ç»™å‡ºäº†æ·±å…¥æµ…å‡ºçš„ä»‹ç»ï¼Œè¯·ä»”ç»†é˜…è¯»å¹¶ç†è§£ã€‚



### ä»»åŠ¡å››ï¼šTransformer & PLM
#### åŸºç¡€çŸ¥è¯†
ä»¥ BERTã€GPT ä¸ºä»£è¡¨çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼ˆPretrain Language Modelï¼ŒPLMï¼‰çš„å‡ºç°ä½¿ NLP ç¿»å¼€äº†æ–°çš„ä¸€é¡µï¼Œç›®å‰çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å¤§å¤šåŸºäº Transformerï¼Œå› æ­¤æƒ³è¦è¿½è¸ªå‰æ²¿ NLP æŠ€æœ¯ï¼Œæˆ‘ä»¬ä¸å¾—ä¸å¯¹ Transformer æœ‰æ·±å…¥çš„ç†è§£ã€‚

è¯·ç»“åˆ Attention Is All You Need åŸè®ºæ–‡ï¼Œè¯»æ‡‚ [The Annotated Transformer](http://nlp.seas.harvard.edu/2018/04/03/attention.html)

å»ºè®®ç»§ç»­é˜…è¯»ï¼š
[encoder-decoder ç»“æ„](https://huggingface.co/blog/encoder-decoder#encoder-decoder)
[å¯è§†åŒ– Transformer](http://jalammar.github.io/illustrated-transformer/)
[å…³äº decode](https://huggingface.co/blog/how-to-generate)

å…³äºé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œè¯·é˜…è¯» BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding å¹¶åšé˜…è¯»ç¬”è®°ï¼Œé‡ç‚¹å…³æ³¨ BERT æ˜¯å¦‚ä½•è®­ç»ƒå‡ºæ¥çš„ï¼Œä»¥åŠå¦‚ä½•å°† BERT åº”ç”¨äºä¸‹æ¸¸ä»»åŠ¡ã€‚
#### Huggingface Transformers
æˆ‘ä»¬åœ¨å®è·µä¸­é€šå¸¸ä¼šä½¿ç”¨ HuggingFaceğŸ¤— çš„ Transformers åº“ï¼Œè¯¥åº“æä¾›äº†åŒ…æ‹¬ BERT å’Œ GPT åœ¨å†…çš„å¸¸è§é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ï¼Œä»£ç é£æ ¼è¾ƒå¥½ï¼Œ[æ–‡æ¡£](https://huggingface.co/docs/transformers/main/index)è¯¦ç»†ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ [Transformers æ•™ç¨‹](https://huggingface.co/course/)è¿›è¡Œå­¦ä¹ ã€‚é‡ç‚¹è¯»æ‡‚:
- [transformers.models.modeling_bert](https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/modeling_bert.py)
#### Huggingface Ecosystem
åœ¨ç¼–å†™æœºå™¨å­¦ä¹ ä»£ç æ—¶ï¼Œæˆ‘ä»¬å¾€å¾€ä¼šå¥—ç”¨æˆç†Ÿçš„æ¨¡æ¿ä½œä¸ºè®­ç»ƒæµç¨‹çš„æ¡†æ¶ã€‚ç›®å‰ï¼ŒHuggingfaceæ‰€æä¾›çš„Traineræ¡†æ¶æ˜¯å¾ˆå¥½çš„é€‰æ‹©ã€‚å¦å¤–ï¼ŒHuggingfaceçš„å¼€æºç”Ÿæ€è¾ƒä¸ºå®Œå–„ (åŒ…æ‹¬ä½†ä¸é™äºdatasets, evaluate, tokenizers (ä¸€èˆ¬ä¸Transformersç»‘å®š), diffusers, huggingface-hub, accelerate)ã€‚äº‹å®ä¸Šï¼Œé€‰æ‹©Huggingface Ecosystemå¯ä»¥å¾ˆå¤§ç¨‹åº¦ç»Ÿä¸€ä»£ç é£æ ¼ï¼Œä»è€Œä¿ƒè¿›åˆä½œå¼€å‘ã€‚
#### åŸºäºHuggingface Trainerçš„åˆ†ç±»ä»»åŠ¡
Huggingface Transformersä»“åº“ä¸­ç»™å‡ºäº†è®¸å¤šç¤ºä¾‹ä»£ç ï¼Œå…¶ä¸­ä¸€ä¸ªéå¸¸æ³›ç”¨çš„æ¨¡æ¿å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°:

https://github.com/huggingface/transformers/tree/28a0811652c680078503a56703327f267b9bdb9a/examples/pytorch/text-classification

ä¸åŒç‰ˆæœ¬çš„Transformerså¯èƒ½ä¼šå¯¹ä»£ç æœ‰åˆ æ”¹ï¼Œæ¨èå­¦ä¹ v4.22.0ä¹‹åçš„ç‰ˆæœ¬ã€‚å…·ä½“çš„ç›®æ ‡åŒ…æ‹¬:
- è·‘é€šGLUEè®­ç»ƒä»£ç 
- Debugä»£ç ï¼Œå°¤å…¶å…³æ³¨
  - å¦‚ä½•ç»§æ‰¿`PretrainedModel` å¹¶å®šåˆ¶Model, å‚è€ƒ [BertForSequenceClassification](https://github.com/huggingface/transformers/blob/main/src/transformers/models/bert/modeling_bert.py#L1506)
  - [`Trainer._inner_training_loop`](https://github.com/huggingface/transformers/blob/main/src/transformers/trainer.py#L1507-L1891) ä¸­çš„ä¸»è¦é€»è¾‘
  - [`TrainingArguments`](https://github.com/huggingface/transformers/blob/main/src/transformers/training_args.py#L121) ä¸­å·²ç»å®ç°å¥½ï¼Œå¹¶ä¸”æ¶‰åŠåˆ°çš„ä¸»è¦å‚æ•°
- å°è¯•ä½¿ç”¨`transformers`é›†æˆçš„`tensorboard`æˆ–è€…`wandb`åŠŸèƒ½å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹
- å°è¯•é­”æ”¹`evaluate`åŠå…¶è°ƒç”¨çš„å­æ–¹æ³•ï¼Œå®ç°è®­ç»ƒè¿‡ç¨‹ä¸­æ›´å¤šæŒ‡æ ‡çš„å¯è§†åŒ–
<!-- å®Œæˆæœ¬å°èŠ‚ä»»åŠ¡åï¼Œå¦‚æœå­¦æœ‰ä½™åŠ›ï¼Œå¯å°è¯•åŸºäº Transformers åº“ï¼Œå®ç°åŸºäº BERT çš„æ–‡æœ¬åˆ†ç±»å’Œ NERã€‚ -->



## æœ¬ä»“åº“çš„ä½¿ç”¨è¯´æ˜

1. æœ‰é—®é¢˜å°±æåœ¨issuesé‡Œé¢ï¼ŒåŒç†ä½ ä¹Ÿå¯ä»¥åœ¨issuesé‡Œé¢æ£€ç´¢æ˜¯å¦å·²ç»æœ‰ä½ é‡åˆ°çš„é—®é¢˜ï¼›
2. mainåˆ†æ”¯æ— æ³•ç›´æ¥ä¿®æ”¹ï¼Œæ‰€æœ‰ä¿®æ”¹å‡éœ€è¦é€šè¿‡æäº¤`Pull requests`æ¥å®ç°ï¼Œå¿…é¡»é€‰æ‹©è‡³å°‘ä¸€ä¸ªreviewerï¼Œæ¨èé€‰æ‹©å¤§å¸ˆå…„`Yifan-Song793`æ¥reviewï¼›
3. git commitçš„è§„èŒƒçœ‹[è¿™é‡Œ](https://juejin.cn/post/6844903793033756680)ã€‚
